{"openapi":"3.1.0","info":{"title":"Minato API","description":"Simple RESTful interface that possible usage ollama on coca.","contact":{"name":"Sidjik","email":"arsenii.milenchuk@student.tuke.sk"},"version":"0.1.0"},"paths":{"/{model_name}":{"get":{"tags":["Minato","Synchronous"],"summary":"Answer On Query","description":"A request that makes a synchronous request and generates a response to the message. \n\n- **message**: message query\n- **keep_alive**: the time that the model will be on the graphics card, for subsequent quick response\n- **numa**: enables or disables NUMA (Non-Uniform Memory Access) to optimize memory management on multiprocessor systems\n- **num_ctx**: sets the size of the context window for generating the next token (the size of the history the model works with)\n- **num_keep**: specifies the number of tokens to preserve when generating text (e.g. to preserve a certain part of the context) \n- **num_batch**: batch size (number of examples processed simultaneously) during training or generation\n- **low_vram**: enables a low-VRAM mode, optimizing performance on systems with limited VRAM.\n- **seed**: sets the seed for random number generation. Allows predictions to be consistent\n- **temperature**: controls the creativity of the model. High values make the responses more varied, low values make them more predictable. Can be from 0 to 1.","operationId":"answer_on_query__model_name__get","parameters":[{"name":"model_name","in":"path","required":true,"schema":{"type":"string","title":"Model Name"}},{"name":"message","in":"query","required":true,"schema":{"type":"string","title":"Message"}},{"name":"system_prompt","in":"query","required":false,"schema":{"type":"string","title":"System Prompt"}},{"name":"keep_alive","in":"query","required":false,"schema":{"type":"integer","default":1,"title":"Keep Alive"}},{"name":"numa","in":"query","required":false,"schema":{"type":"boolean","default":true,"title":"Numa"}},{"name":"num_ctx","in":"query","required":false,"schema":{"type":"integer","default":4096,"title":"Num Ctx"}},{"name":"num_keep","in":"query","required":false,"schema":{"type":"integer","default":4096,"title":"Num Keep"}},{"name":"num_batch","in":"query","required":false,"schema":{"type":"integer","default":1,"title":"Num Batch"}},{"name":"low_vram","in":"query","required":false,"schema":{"type":"boolean","default":false,"title":"Low Vram"}},{"name":"seed","in":"query","required":false,"schema":{"type":"integer","default":21,"title":"Seed"}},{"name":"temperature","in":"query","required":false,"schema":{"type":"integer","default":0,"title":"Temperature"}}],"responses":{"200":{"description":"Succesfully generated answer","content":{"application/json":{"schema":{}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/stream/{model_name}":{"get":{"tags":["Minato","Asynchronous"],"summary":"Async Answer On Query","description":"A request that makes a asynchronous request and generates a response to the message. \n\n- **message**: message query\n- **keep_alive**: the time that the model will be on the graphics card, for subsequent quick response\n- **numa**: enables or disables NUMA (Non-Uniform Memory Access) to optimize memory management on multiprocessor systems\n- **num_ctx**: sets the size of the context window for generating the next token (the size of the history the model works with)\n- **num_keep**: specifies the number of tokens to preserve when generating text (e.g. to preserve a certain part of the context) \n- **num_batch**: batch size (number of examples processed simultaneously) during training or generation\n- **low_vram**: enables a low-VRAM mode, optimizing performance on systems with limited VRAM.\n- **seed**: sets the seed for random number generation. Allows predictions to be consistent\n- **temperature**: controls the creativity of the model. High values make the responses more varied, low values make them more predictable. Can be from 0 to 1.","operationId":"async_answer_on_query_stream__model_name__get","parameters":[{"name":"model_name","in":"path","required":true,"schema":{"type":"string","title":"Model Name"}},{"name":"message","in":"query","required":true,"schema":{"type":"string","title":"Message"}},{"name":"system_prompt","in":"query","required":false,"schema":{"type":"string","title":"System Prompt"}},{"name":"keep_alive","in":"query","required":false,"schema":{"type":"integer","default":1,"title":"Keep Alive"}},{"name":"numa","in":"query","required":false,"schema":{"type":"boolean","default":true,"title":"Numa"}},{"name":"num_ctx","in":"query","required":false,"schema":{"type":"integer","default":4096,"title":"Num Ctx"}},{"name":"num_keep","in":"query","required":false,"schema":{"type":"integer","default":4096,"title":"Num Keep"}},{"name":"num_batch","in":"query","required":false,"schema":{"type":"integer","default":1,"title":"Num Batch"}},{"name":"low_vram","in":"query","required":false,"schema":{"type":"boolean","default":false,"title":"Low Vram"}},{"name":"seed","in":"query","required":false,"schema":{"type":"integer","default":21,"title":"Seed"}},{"name":"temperature","in":"query","required":false,"schema":{"type":"integer","default":0,"title":"Temperature"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/vision/{model_name}":{"post":{"tags":["Minato","Synchronous","Multimodal"],"summary":"Answer On Multimodal Query","description":"A query that allows the use of multimodal models together with images and text message.\n\n**model_name**: define model name that you want to use\n**message**: text message to model\n**images**: array with images, that will get to input\n- **numa**: enables or disables NUMA (Non-Uniform Memory Access) to optimize memory management on multiprocessor systems\n- **num_ctx**: sets the size of the context window for generating the next token (the size of the history the model works with)\n- **num_keep**: specifies the number of tokens to preserve when generating text (e.g. to preserve a certain part of the context) \n- **num_batch**: batch size (number of examples processed simultaneously) during training or generation\n- **low_vram**: enables a low-VRAM mode, optimizing performance on systems with limited VRAM.\n- **seed**: sets the seed for random number generation. Allows predictions to be consistent\n- **temperature**: controls the creativity of the model. High values make the responses more varied, low values make them more predictable. Can be from 0 to 1.","operationId":"answer_on_multimodal_query_vision__model_name__post","parameters":[{"name":"model_name","in":"path","required":true,"schema":{"type":"string","title":"Model Name"}},{"name":"message","in":"query","required":true,"schema":{"type":"string","title":"Message"}},{"name":"system_prompt","in":"query","required":false,"schema":{"type":"string","title":"System Prompt"}},{"name":"keep_alive","in":"query","required":false,"schema":{"type":"integer","default":1,"title":"Keep Alive"}},{"name":"numa","in":"query","required":false,"schema":{"type":"boolean","default":true,"title":"Numa"}},{"name":"num_ctx","in":"query","required":false,"schema":{"type":"integer","default":4096,"title":"Num Ctx"}},{"name":"num_keep","in":"query","required":false,"schema":{"type":"integer","default":4096,"title":"Num Keep"}},{"name":"num_batch","in":"query","required":false,"schema":{"type":"integer","default":1,"title":"Num Batch"}},{"name":"low_vram","in":"query","required":false,"schema":{"type":"boolean","default":false,"title":"Low Vram"}},{"name":"seed","in":"query","required":false,"schema":{"type":"integer","default":21,"title":"Seed"}},{"name":"temperature","in":"query","required":false,"schema":{"type":"integer","default":0,"title":"Temperature"}}],"requestBody":{"required":true,"content":{"multipart/form-data":{"schema":{"$ref":"#/components/schemas/Body_answer_on_multimodal_query_vision__model_name__post"}}}},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/stream/vision/{model_name}":{"post":{"tags":["Minato","Asynchronous","Multimodal"],"summary":"Async Answer On Multimodal Query","description":"A query that allows the use of multimodal models together with images and text message.\nThe function produces an asynchronous response.\n\n**model_name**: define model name that you want to use\n**message**: text message to model\n**images**: array with images, that will get to input\n- **numa**: enables or disables NUMA (Non-Uniform Memory Access) to optimize memory management on multiprocessor systems\n- **num_ctx**: sets the size of the context window for generating the next token (the size of the history the model works with)\n- **num_keep**: specifies the number of tokens to preserve when generating text (e.g. to preserve a certain part of the context) \n- **num_batch**: batch size (number of examples processed simultaneously) during training or generation\n- **low_vram**: enables a low-VRAM mode, optimizing performance on systems with limited VRAM.\n- **seed**: sets the seed for random number generation. Allows predictions to be consistent\n- **temperature**: controls the creativity of the model. High values make the responses more varied, low values make them more predictable. Can be from 0 to 1.","operationId":"async_answer_on_multimodal_query_stream_vision__model_name__post","parameters":[{"name":"model_name","in":"path","required":true,"schema":{"type":"string","title":"Model Name"}},{"name":"message","in":"query","required":true,"schema":{"type":"string","title":"Message"}},{"name":"system_prompt","in":"query","required":false,"schema":{"type":"string","title":"System Prompt"}},{"name":"keep_alive","in":"query","required":false,"schema":{"type":"integer","default":1,"title":"Keep Alive"}},{"name":"numa","in":"query","required":false,"schema":{"type":"boolean","default":true,"title":"Numa"}},{"name":"num_ctx","in":"query","required":false,"schema":{"type":"integer","default":4096,"title":"Num Ctx"}},{"name":"num_keep","in":"query","required":false,"schema":{"type":"integer","default":4096,"title":"Num Keep"}},{"name":"num_batch","in":"query","required":false,"schema":{"type":"integer","default":1,"title":"Num Batch"}},{"name":"low_vram","in":"query","required":false,"schema":{"type":"boolean","default":false,"title":"Low Vram"}},{"name":"seed","in":"query","required":false,"schema":{"type":"integer","default":21,"title":"Seed"}},{"name":"temperature","in":"query","required":false,"schema":{"type":"integer","default":0,"title":"Temperature"}}],"requestBody":{"required":true,"content":{"multipart/form-data":{"schema":{"$ref":"#/components/schemas/Body_async_answer_on_multimodal_query_stream_vision__model_name__post"}}}},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/install/{model_name}":{"post":{"tags":["Minato","Settings"],"summary":"Download Model","description":"Allows you download model to the server. You can use model name that you find on ollama mirror website\n\n**model_name**: define model name that will download from ollama mirror\n\nSimply return status of downlod.","operationId":"download_model_install__model_name__post","parameters":[{"name":"model_name","in":"path","required":true,"schema":{"type":"string","title":"Model Name"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/models_list/":{"get":{"tags":["Minato","Settings"],"summary":"Get List Available Models","description":"Return list with info about available models, such as\n\n- **Name**\n- **Size in MB**\n- **Format** if available for model\n- **Family** if available for model\n- **Size of parameters** if available for model\n- **Quantization level** if available for model","operationId":"get_list_available_models_models_list__get","responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}}}}}},"components":{"schemas":{"Body_answer_on_multimodal_query_vision__model_name__post":{"properties":{"images":{"items":{"type":"string","format":"binary"},"type":"array","title":"Images"}},"type":"object","required":["images"],"title":"Body_answer_on_multimodal_query_vision__model_name__post"},"Body_async_answer_on_multimodal_query_stream_vision__model_name__post":{"properties":{"images":{"items":{"type":"string","format":"binary"},"type":"array","title":"Images"}},"type":"object","required":["images"],"title":"Body_async_answer_on_multimodal_query_stream_vision__model_name__post"},"HTTPValidationError":{"properties":{"detail":{"items":{"$ref":"#/components/schemas/ValidationError"},"type":"array","title":"Detail"}},"type":"object","title":"HTTPValidationError"},"ValidationError":{"properties":{"loc":{"items":{"anyOf":[{"type":"string"},{"type":"integer"}]},"type":"array","title":"Location"},"msg":{"type":"string","title":"Message"},"type":{"type":"string","title":"Error Type"}},"type":"object","required":["loc","msg","type"],"title":"ValidationError"}}}}